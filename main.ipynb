{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spotify_download as sd\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import db_util\n",
    "import pandas as pd\n",
    "import embedding_generation\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "import cv2\n",
    "from skimage.segmentation import slic\n",
    "from skimage.color import label2rgb\n",
    "import tqdm\n",
    "import vtracer\n",
    "from FLAS import assign_positions_to_images\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 4 playlists...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:19<00:00,  7.85it/s]\n",
      "100%|██████████| 150/150 [00:00<00:00, 56349.81it/s]\n",
      "100%|██████████| 150/150 [00:00<00:00, 59566.90it/s]\n",
      "100%|██████████| 1/1 [00:13<00:00, 13.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 451/451 [01:45<00:00,  4.28it/s]\n"
     ]
    }
   ],
   "source": [
    "playlists = [\n",
    "    \"37i9dQZF1DX4o1oenSJRJd\", # All Out 2000s\n",
    "    \"37i9dQZF1DX5Ejj0EkURtP\", # All Out 2010s\n",
    "    \"37i9dQZF1DX2M1RktxUUHG\", # All Out 2020s\n",
    "    \"1f6ze3bR0LdhO7zp3V56J5\" # Explode by Big Freedia\n",
    "]\n",
    "\n",
    "# find path for spotdl executable\n",
    "spotdl_path = !which spotdl\n",
    "spotdl_path = spotdl_path[0]\n",
    "\n",
    "tracks = []\n",
    "print(f\"Downloading {len(playlists)} playlists...\")\n",
    "if not os.path.exists(\"tracks\"):\n",
    "    os.mkdir(\"tracks\")\n",
    "for playlist in playlists:\n",
    "    tracks.extend(list(sd.download_playlist(playlist, \"tracks\", spotdl_path)))\n",
    "\n",
    "print(\"Building database...\")\n",
    "sd.build_db(tracks_dir=\"tracks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Audio Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "tracks_df = db_util.get_tracks()\n",
    "embedding_generation.embed_tracks(tracks_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing embedding spacing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 22.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images (phase 1)...\n",
      "Generating images (phase 2)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 451/451 [03:28<00:00,  2.17it/s]\n"
     ]
    }
   ],
   "source": [
    "img_resolution = (128, 128)\n",
    "source_img_dir = \"style_images\"\n",
    "max_source_imgs = 500\n",
    "target_img_dir = \"images\"\n",
    "n_pca_components = 64\n",
    "blur_radius = 63\n",
    "\n",
    "tracks = db_util.get_tracks()\n",
    "\n",
    "source_img_paths = glob.glob(os.path.join(source_img_dir, \"*.jpg\"))\n",
    "if len(source_img_paths) == 0:\n",
    "    print(\"No source images found!\")\n",
    "elif len(source_img_paths) > max_source_imgs:\n",
    "    np.random.seed(0)\n",
    "    source_img_paths = np.random.choice(source_img_paths, max_source_imgs, replace=False)\n",
    "source_imgs = [np.array(Image.open(path).resize(img_resolution)) for path in source_img_paths]\n",
    "source_imgs = [cv2.GaussianBlur(img, (blur_radius, blur_radius), 0) for img in source_imgs]\n",
    "for i in range(len(source_imgs)):\n",
    "    if len(source_imgs[i].shape) == 2:\n",
    "        source_imgs[i] = np.dstack([source_imgs[i]]*3)\n",
    "    else:\n",
    "        source_imgs[i] = source_imgs[i][:,:,:3]\n",
    "X = np.array([(img if len(img.shape) == 3 else np.dstack([img,img,img])) for img in source_imgs])\n",
    "X = X.reshape(len(source_imgs), -1)\n",
    "pca = PCA(n_components=n_pca_components)\n",
    "pca.fit(X)\n",
    "principal_components = pca.components_\n",
    "\n",
    "embeddings = np.array(tracks.embedding.tolist())\n",
    "embedding_pca = PCA(n_components=n_pca_components)\n",
    "embeddings_reduced = embedding_pca.fit_transform(embeddings)\n",
    "\n",
    "embeddings_reduced = embedding_generation.optimize_spacing(embeddings_reduced)\n",
    "\n",
    "tracks[f\"embedding_{n_pca_components}\"] = [embedding for embedding in embeddings_reduced]\n",
    "\n",
    "print(\"Generating images (phase 1)...\")\n",
    "for i, track in tracks.iterrows():\n",
    "    track_id = track[\"id\"]\n",
    "    embedding = track[f\"embedding_{n_pca_components}\"]\n",
    "    image = np.dot(embedding, principal_components).reshape(*img_resolution, 3)\n",
    "    image -= image.min()\n",
    "    image /= image.max()\n",
    "    image *= 255\n",
    "    image = image.astype(np.uint8)\n",
    "    plt.imsave(os.path.join(\"track_images\", \"blurry\", f\"{track_id}.png\"), image)\n",
    "\n",
    "print(\"Generating images (phase 2)...\")\n",
    "for i, track in tqdm.tqdm(tracks.iterrows(), total=len(tracks)):\n",
    "    track_id = track[\"id\"]\n",
    "    blurry = plt.imread(f\"track_images/blurry/{track_id}.png\")[:, :, :3]\n",
    "    # cluster the image\n",
    "    labels = slic(blurry, n_segments=16, convert2lab=True, enforce_connectivity=False)\n",
    "    # recreate the image\n",
    "    reconstructed = label2rgb(labels, blurry, kind='avg')\n",
    "    plt.imsave(f\"track_images/flattened/{track_id}.png\", reconstructed)\n",
    "    vtracer.convert_image_to_svg_py(f\"track_images/flattened/{track_id}.png\", f\"track_images/vectorized/{track_id}.svg\")\n",
    "    !inkscape -w 256 -h 256 track_images/vectorized/{track_id}.svg -o track_images/rasterized/{track_id}.png > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort with LAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 0 images to make grid shape possible\n",
      "number of paths: 451\n",
      "number of unique paths: 451\n",
      "Grid shape: (11, 41)\n",
      "Number of images: 451\n",
      ".........\n",
      "Sorted with LAS in 0.099 seconds\n",
      "number of ids: 451\n",
      "number of unique ids: 451\n"
     ]
    }
   ],
   "source": [
    "assign_positions_to_images(\"track_images/rasterized\", feature_vector_size=8, max_images=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move to Viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating clips...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "451it [00:00, 27809.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying images to viewer...\n",
      "Copying layout to viewer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tracks_df = db_util.get_tracks()\n",
    "overwrite_clips = False\n",
    "\n",
    "# Create 15 second clips of each track\n",
    "print(\"Creating clips...\")\n",
    "for i, track in tqdm.tqdm(tracks_df.iterrows()):\n",
    "    if os.path.exists(f\"Viewer/track_clips/{track['id']}.mp3\") and not overwrite_clips:\n",
    "        continue\n",
    "    audio_path = track[\"audio_path\"]\n",
    "    audio, sample_rate = sf.read(audio_path)\n",
    "    samples_per_clip = sample_rate * 15\n",
    "    middle = len(audio) // 2\n",
    "    audio = audio[middle - samples_per_clip // 2:middle + samples_per_clip // 2]\n",
    "    sf.write(f\"Viewer/track_clips/{track['id']}.mp3\", audio, sample_rate)\n",
    "\n",
    "print(\"Copying images to viewer...\")\n",
    "# Copy the images to the viewer\n",
    "for i, track in tracks_df.iterrows():\n",
    "    # shutil.copy(f\"track_images/rasterized/{track['id']}.png\", f\"Viewer/track_images/{track['id']}.png\")\n",
    "    shutil.copy(f\"track_images/vectorized/{track['id']}.svg\", f\"Viewer/track_images/{track['id']}.svg\")\n",
    "\n",
    "print(\"Copying layout to viewer...\")\n",
    "# Copy the sorted layout to the viewer\n",
    "gridded_ids = np.loadtxt(\"gridded_ids.csv\", dtype=str)\n",
    "nested_list = []\n",
    "for line in gridded_ids:\n",
    "    nested_list.append(line.split(\",\"))\n",
    "\n",
    "js_list_string = nested_list.__str__().replace(\"'\", \"\\\"\")\n",
    "js_list_string = \"var grid_ids = \" + js_list_string\n",
    "with open(\"Viewer/data.js\", \"w\") as f:\n",
    "    f.write(js_list_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
